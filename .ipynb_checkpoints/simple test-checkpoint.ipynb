{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moved-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255.0\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educational-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(60000,1)\n",
    "y_test = y_test.reshape(10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clean-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "x_train_tf = x_train_tf.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "\n",
    "y_train_tf = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "y_train_tf = y_train_tf.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "manufactured-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Model):\n",
    "    def __init__(self, input_dim, hidden1, hidden2, hidden3, outputs):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.hidden1 = layers.Dense(hidden1, activation='relu', name='hidden1') # 500\n",
    "        self.hidden2 = layers.Dense(hidden2, activation='relu', name='hidden2') # 300\n",
    "        self.hidden3 = layers.Dense(hidden3, activation='relu', name='hidden3') # 100\n",
    "        self.hidden4 = layers.Dense(10, name='hidden4', activation = 'softmax')\n",
    "        #self.outputs = layers.Softmax(name = 'output') # 10\n",
    "        \n",
    "        #self.droupout = Droupout(0.2)\n",
    "        self.input_dim = input_dim\n",
    "    \n",
    "    def build_graph(self):\n",
    "        inputs_ = layers.Input(shape=self.input_dim, name = 'inputs')\n",
    "        return Model(inputs=inputs_, outputs=self.call(inputs_))\n",
    "        #self._init_graph_network(inputs=self.input_layer,outputs=self.out)\n",
    "        \n",
    "#     def model(self):\n",
    "#         x = layers.Input(shape=self.input_dim)\n",
    "#         return Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "    def call(self, input_data, training=False):\n",
    "        x = self.hidden1(input_data)\n",
    "        #if training == True:\n",
    "            #x = self.droupout(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        #x = self.outputs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(784, 500, 300, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noted-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "hidden4 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "output (Softmax)             (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 573,910\n",
      "Trainable params: 573,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.build_graph().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intended-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              multiple                  392500    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              multiple                  150300    \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              multiple                  30100     \n",
      "_________________________________________________________________\n",
      "hidden4 (Dense)              multiple                  1010      \n",
      "_________________________________________________________________\n",
      "output (Softmax)             multiple                  0         \n",
      "=================================================================\n",
      "Total params: 573,910\n",
      "Trainable params: 573,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "junior-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(mlp.build_graph(), show_shapes=True, show_layer_names=True, rankdir='TB', dpi=100, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seeing-lloyd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 7, 4, 1, 8, 9, 3, 6, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "alternative-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,args, train, test):\n",
    "        self.args = args\n",
    "        self.x_train = train[0]\n",
    "        self.y_train = train[1]\n",
    "        \n",
    "        self.x_test = test[0]\n",
    "        self.y_test = test[1]\n",
    "    \n",
    "    def train_mlp1(self):\n",
    "        mlp = MLP(784, 500, 300, 100, 10).build_graph()\n",
    "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        #metric = 'sparse_categorical_accuracy'\n",
    "\n",
    "        mlp.compile(optimizer=optimizer, loss=loss_object, metrics = metric)#metrics=['accuracy'])\n",
    "        hist = mlp.fit(x=self.x_train, y=self.y_train, batch_size = self.args['batch'], epochs=self.args['epochs'], )\n",
    "        \n",
    "        return mlp\n",
    "    \n",
    "    \n",
    "    def train_mlp2(self):\n",
    "        \n",
    "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "        \n",
    "        mlp = MLP(784, 500, 300, 100, 10)\n",
    "        \n",
    "        N = self.x_train.shape[0]\n",
    "        BS = self.args['batch']\n",
    "        BN = int(ceil(N / BS))\n",
    "        \n",
    "        for epoch in range(self.args['epochs']):\n",
    "            print(f\"Start of epoch {epoch}\")\n",
    "            ind = np.random.permutation(N)\n",
    "            x_train = self.x_train[ind]\n",
    "            y_train = self.y_train[ind]\n",
    "            g_batch = tqdm(range(BN))\n",
    "            # Iterate over the batches of the dataset.\n",
    "            loss_tracker = 0\n",
    "            for step in g_batch:\n",
    "                x_batch = x_train[step * BS: (step + 1) * BS]\n",
    "                y_batch = y_train[step * BS: (step + 1) * BS]\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = mlp(x_batch_train)\n",
    "                    loss = loss_object(y_batch, output)\n",
    "                    #loss += sum(mlp.losses) \n",
    "\n",
    "                grads = tape.gradient(loss, mlp.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(grads, mlp.trainable_weights))\n",
    "\n",
    "                train_loss(loss)\n",
    "                train_accuracy(y_batch_train, output)\n",
    "                print(train_loss)\n",
    "                if step % 100 == 0:\n",
    "                    \n",
    "                    template = 'Step: {}, 손실: {:.3f}, 정확도: {:.3f}'\n",
    "                    print(template.format(step,\n",
    "                                          train_loss.result(),\n",
    "                                          train_accuracy.result()*100))\n",
    "                    \n",
    "                    #print(f\"Step: {step}, loss: {train_loss.result()}\")\n",
    "                    #print(\"step %d: mean loss = %.4f\" % (step, train_loss.result()))\n",
    "            print(f\"epoch: {epoch+1}, Loss: {loss_tracker}\")\n",
    "    \n",
    "    \n",
    "    def train_mlp(self):\n",
    "        \n",
    "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "        #train_accuracy = tf.keras.metrics.Accuracy(name = 'traom_accuracy')\n",
    "\n",
    "        \n",
    "        mlp = MLP(784, 500, 300, 100, 10).build_graph()\n",
    "        for epoch in range(self.args['epochs']):\n",
    "            print(f\"Start of epoch {epoch+1}\")\n",
    "            # Iterate over the batches of the dataset.\n",
    "            loss_tracker = []\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(zip(self.x_train, self.y_train)):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = mlp(x_batch_train)\n",
    "                    loss = loss_object(y_batch_train, output)\n",
    "                    #loss += sum(mlp.losses) \n",
    "\n",
    "                grads = tape.gradient(loss, mlp.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(grads, mlp.trainable_weights))\n",
    "                #train_loss.update_state(loss)\n",
    "                #train_accuracy.update_state(y_batch_train, output)\n",
    "\n",
    "                train_loss(loss)\n",
    "                train_accuracy(y_batch_train, output)\n",
    " \n",
    "\n",
    "                if step % 100 == 0:\n",
    "                    template = 'Step: {}, 손실: {:.3f}, 정확도: {:.3f}'\n",
    "                    print(template.format(step,\n",
    "                                          train_loss.result(),\n",
    "                                          train_accuracy.result()*100))\n",
    "                   \n",
    "            print(f\"epoch: {epoch+1}, Loss: {train_loss.result()}, Accuracy: {train_accuracy.result()}, loss metric: {train_loss.result()}\")\n",
    "        \n",
    "                    \n",
    "    def eval_step(self):\n",
    "        pass\n",
    "        #prediction = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "catholic-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'epochs': 2,\n",
    "       'batch': 64}\n",
    "\n",
    "simple_mlp1 = Trainer(args, train=[x_train, y_train], test=[x_test, y_test])\n",
    "simple_mlp = Trainer(args, train=[x_train_tf, y_train_tf], test=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "interior-component",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x20343355b80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_mlp1.train_mlp1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hazardous-shoulder",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Step: 0, 손실: 2.346, 정확도: 12.500\n",
      "Step: 100, 손실: 2.312, 정확도: 10.164\n",
      "Step: 200, 손실: 2.310, 정확도: 10.253\n",
      "Step: 300, 손실: 2.308, 정확도: 10.486\n",
      "Step: 400, 손실: 2.307, 정확도: 10.583\n",
      "Step: 500, 손실: 2.306, 정확도: 10.598\n",
      "Step: 600, 손실: 2.306, 정확도: 10.672\n",
      "Step: 700, 손실: 2.305, 정확도: 10.790\n",
      "Step: 800, 손실: 2.305, 정확도: 10.778\n",
      "Step: 900, 손실: 2.305, 정확도: 10.781\n",
      "epoch: 1, Loss: 2.304502248764038, Accuracy: 0.10778333246707916, loss metric: 2.304502248764038\n",
      "Start of epoch 2\n",
      "Step: 0, 손실: 2.305, 정확도: 10.782\n",
      "Step: 100, 손실: 2.304, 정확도: 10.824\n",
      "Step: 200, 손실: 2.304, 정확도: 10.850\n",
      "Step: 300, 손실: 2.304, 정확도: 10.927\n",
      "Step: 400, 손실: 2.304, 정확도: 10.957\n",
      "Step: 500, 손실: 2.304, 정확도: 10.973\n",
      "Step: 600, 손실: 2.303, 정확도: 11.003\n",
      "Step: 700, 손실: 2.303, 정확도: 11.019\n",
      "Step: 800, 손실: 2.303, 정확도: 11.024\n",
      "Step: 900, 손실: 2.303, 정확도: 10.994\n",
      "epoch: 2, Loss: 2.303077220916748, Accuracy: 0.10989999771118164, loss metric: 2.303077220916748\n"
     ]
    }
   ],
   "source": [
    "#model = simple_mlp.train_mlp1()\n",
    "simple_mlp.train_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "democratic-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "hidden4 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "output (Softmax)             (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 573,910\n",
      "Trainable params: 573,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "controversial-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = Model(model.get_layer('inputs').input, model.get_layer('hidden2').output)\n",
    "#stat_AE = Model(combination.get_layer('stat_inputs').input, combination.get_layer('STAT_AE').output)\n",
    "#model.get_layer('hidden1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dated-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 300)               150300    \n",
      "=================================================================\n",
      "Total params: 542,800\n",
      "Trainable params: 542,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "part.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "modern-threat",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'Input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-da830df310a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m768\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidden3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'Input'"
     ]
    }
   ],
   "source": [
    "Model(layers.Input(768).Input, model.get_layer('hidden3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "nervous-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "practical-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(64, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "upper-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for key, values in enumerate(zip(y_train, y_test)):\n",
    "    print(values[0])\n",
    "    print(values[1])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
